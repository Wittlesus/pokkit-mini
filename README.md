# pokkit-mini

Fine-tuned small language model for the Pokkit AI agent. Trained specifically on phone-control tasks, tool calling, and Pokkit's personality.

## Base Model

**Qwen2.5-3B-Instruct** — best-in-class tool calling at 3B params.  
Fallback: **Phi-3.5-mini-instruct** (3.8B) — slightly larger, excellent reasoning.

## Why fine-tune?

A generic model wastes tokens figuring out what Pokkit can do. pokkit-mini:
- Already knows all built-in tools and their exact schemas
- Calls tools immediately without hedging
- Has Pokkit's personality baked in (no system prompt needed for basics)
- Refuses background automation correctly (Anthropic-style compliance)
- Understands custom plugin patterns

## Training

- **Method**: LoRA (rank 16) via Unsloth — 4x faster, runs on RTX 3060+ or free Colab T4
- **Dataset**: ~2,000 synthetic conversations generated by `generate_dataset.py`
- **Epochs**: 3
- **Time**: ~45 min on T4, ~15 min on A100

## Files

```
pokkit-mini/
  generate_dataset.py     ← Synthetic training data generator
  train.py                ← Unsloth LoRA fine-tuning script  
  export.py               ← Export to GGUF (Ollama) + ONNX
  Modelfile               ← Ollama Modelfile for distribution
  data/
    train.jsonl           ← Generated training data
    eval.jsonl            ← Held-out evaluation set
  notebooks/
    train_colab.ipynb     ← Google Colab notebook (free T4 GPU)
```

## Quick Start

### Generate training data
```bash
python generate_dataset.py --output data/train.jsonl --count 2000
```

### Train (local GPU)
```bash
pip install unsloth
python train.py --model qwen2.5-3b --data data/train.jsonl --output ./pokkit-mini-lora
```

### Train (Google Colab — free)
Open `notebooks/train_colab.ipynb` in Colab, select T4 GPU runtime, run all cells.

### Export to Ollama
```bash
python export.py --lora ./pokkit-mini-lora --format gguf --output ./pokkit-mini.gguf
ollama create pokkit-mini -f Modelfile
ollama run pokkit-mini
```

### Use in Pokkit app
In Settings → Provider → Ollama → Model → `pokkit-mini`

## Dataset Format

Each example is a conversation in ChatML format with tool calls:

```json
{
  "messages": [
    {"role": "system", "content": "You are Pokkit..."},
    {"role": "user", "content": "Set an alarm for 7am tomorrow"},
    {"role": "assistant", "content": "", "tool_calls": [
      {"name": "set_alarm", "arguments": {"title": "Wake up", "datetime": "2026-02-19T07:00:00"}}
    ]},
    {"role": "tool", "content": "{\"success\": true}"},
    {"role": "assistant", "content": "Done! ⏰ Alarm set for 7am tomorrow."}
  ]
}
```
