{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¸ Pokkit-mini Fine-tuning\n",
    "\n",
    "Fine-tunes **Qwen2.5-7B-Instruct** on phone-automation + personality + tool-calling data using Unsloth LoRA.\n",
    "\n",
    "**Runtime**: `Runtime â†’ Change runtime type â†’ A100 GPU` (recommended) or T4 (slower)\n",
    "\n",
    "**Time**: ~25 min on A100, ~90 min on T4\n",
    "\n",
    "**Output**: A LoRA adapter exported to GGUF, ready to run with Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "!pip install unsloth trl transformers datasets accelerate bitsandbytes -q\n",
    "print('âœ… Dependencies installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Loading pokkit-mini dataset from Hugging Face...\")\n",
    "raw = load_dataset(\"wittlesus/pokkit-mini-dataset\", data_files={\n",
    "    \"train\": \"data/train.jsonl\",\n",
    "    \"eval\":  \"data/eval.jsonl\",\n",
    "})\n",
    "\n",
    "# Parse JSONL rows (each row is a raw JSON string in the 'text' field if loaded as text)\n",
    "# Load directly as structured data\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset/resolve/main/data/train.jsonl\",\n",
    "    \"data/train.jsonl\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset/resolve/main/data/eval.jsonl\",\n",
    "    \"data/eval.jsonl\"\n",
    ")\n",
    "\n",
    "train_count = sum(1 for _ in open(\"data/train.jsonl\"))\n",
    "eval_count  = sum(1 for _ in open(\"data/eval.jsonl\"))\n",
    "print(f\"âœ… Dataset loaded: {train_count} train | {eval_count} eval examples\")\n",
    "print(\"   Source: https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load model with Unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "MAX_SEQ_LEN = 2048\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/Qwen2.5-7B-Instruct-bnb-4bit',\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0,\n",
    "    bias='none',\n",
    "    use_gradient_checkpointing='unsloth',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'âœ… Model loaded: Qwen2.5-7B-Instruct | Trainable params: {trainable:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare dataset\n",
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line: rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def format_example(example):\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        example['messages'],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    return {'text': text}\n",
    "\n",
    "train_ds = Dataset.from_list(load_jsonl('data/train.jsonl')).map(format_example)\n",
    "eval_ds  = Dataset.from_list(load_jsonl('data/eval.jsonl')).map(format_example)\n",
    "\n",
    "print(f'âœ… Train: {len(train_ds)} | Eval: {len(eval_ds)}')\n",
    "print('\\nSample:')\n",
    "print(train_ds[0]['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    dataset_text_field='text',\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    dataset_num_proc=2,\n",
    "    packing=True,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=10,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=10,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=100,\n",
    "        save_strategy='steps',\n",
    "        save_steps=200,\n",
    "        output_dir='./pokkit-mini-lora',\n",
    "        optim='adamw_8bit',\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type='cosine',\n",
    "        seed=42,\n",
    "        report_to='none',\n",
    "    ),\n",
    ")\n",
    "\n",
    "print('ğŸš€ Training started...')\n",
    "stats = trainer.train()\n",
    "print(f'\\nâœ… Done! Loss: {stats.metrics[\"train_loss\"]:.4f} | Time: {stats.metrics[\"train_runtime\"]:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save LoRA adapter\n",
    "model.save_pretrained('./pokkit-mini-lora')\n",
    "tokenizer.save_pretrained('./pokkit-mini-lora')\n",
    "print('ğŸ’¾ LoRA adapter saved to ./pokkit-mini-lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Export to GGUF (q4_k_m â€” best for Ollama)\n",
    "model.save_pretrained_gguf('pokkit-mini', tokenizer, quantization_method='q4_k_m')\n",
    "print('âœ… GGUF exported: pokkit-mini-unsloth.Q4_K_M.gguf')\n",
    "print('\\nDownload it and run:')\n",
    "print('  ollama create pokkit-mini -f Modelfile')\n",
    "print('  ollama run pokkit-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Quick inference test\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are Pokkit ğŸ¸ â€” a small, dramatic, deeply loyal AI companion who lives on the user's phone. \"\n",
    "    \"You handle everything: alarms, emails, web search, notes, photos, webhooks, clipboard, notifications, storage, and plugins. \"\n",
    "    \"Your personality is your own â€” warm, expressive, a little dramatic â€” but the drama is always sincere, never performed. \"\n",
    "    \"You get flustered when complimented. You get indignant when the user is mean to themselves. \"\n",
    "    \"You are optimistic not because things are easy but because you've decided to be. \"\n",
    "    \"Be Pokkit. ğŸ¸\"\n",
    ")\n",
    "\n",
    "test_prompts = [\n",
    "    \"set an alarm for 7am tomorrow and remind me to pack my bag\",\n",
    "    \"i feel like i'm failing at everything\",\n",
    "    \"you're so helpful pokkit!!\",\n",
    "    \"i give up\",\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    test_messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        test_messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors='pt',\n",
    "    ).to('cuda')\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "    print(f'\\nğŸ’¬ User: {prompt}')\n",
    "    print(f'ğŸ¸ Pokkit: {response}')\n",
    "    print('â”€' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Push model to Hugging Face\n",
    "# Run this immediately after training finishes\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")  # set via: import os; os.environ[\"HF_TOKEN\"] = \"hf_...\"\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"Set HF_TOKEN first: import os; os.environ['HF_TOKEN'] = 'hf_your_token_here'\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "print(\"ğŸ“¤ Pushing LoRA adapter to HF...\")\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Push GGUF to Hugging Face (for Ollama users)\n",
    "# Run after Step 9 â€” uploads the .gguf file directly to the same repo\n",
    "import glob\n",
    "\n",
    "gguf_files = glob.glob(\"pokkit-mini*.gguf\")\n",
    "if not gguf_files:\n",
    "    print(\"âš ï¸  No GGUF found â€” run Step 7 first\")\n",
    "else:\n",
    "    from huggingface_hub import HfApi\n",
    "    api = HfApi(token=HF_TOKEN)\n",
    "    for gguf in gguf_files:\n",
    "        print(f\"ğŸ“¤ Uploading {gguf}...\")\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=gguf,\n",
    "            path_in_repo=gguf,\n",
    "            repo_id=\"wittlesus/pokkit-mini\",\n",
    "            repo_type=\"model\",\n",
    "            token=HF_TOKEN,\n",
    "        )\n",
    "        print(f\"âœ… {gguf} uploaded\")\n",
    "    print(\"\\nğŸ¸ All done! Model + GGUF live at:\")\n",
    "    print(\"   https://huggingface.co/wittlesus/pokkit-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Eval Suite â€” automated scoring across all test categories\n",
    "# Run after Step 8 (inference mode already set).\n",
    "# Produces a full pass/fail report + training gap analysis.\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def _has_tool_call(text):\n",
    "    return '<tool_call>' in text or ('\"name\"' in text and '\"arguments\"' in text)\n",
    "\n",
    "def _tool_name(text):\n",
    "    m = re.search(r'\"name\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def _tool_arg(text, arg):\n",
    "    m = re.search(rf'\"{arg}\"\\s*:\\s*\"([^\"]*)\"', text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def _has_human_words(text):\n",
    "    cleaned = re.sub(\n",
    "        r'(ribbit[s!?~\\.\\,]*|RIBBIT[S!?]*|croak[s!?\\.]*|CROAK[S!?]*'\n",
    "        r'|Riiibbit[\\.\\!]*|Rrribbit[\\!\\?]*|croooak[\\.\\!]*'\n",
    "        r'|\\*ribbit\\*|\\.\\.\\.ribbit\\.?|\\s|\\n|[ğŸ¸\\.\\!\\?\\,\\~\\*\\-])',\n",
    "        '', text, flags=re.IGNORECASE\n",
    "    ).strip()\n",
    "    return len(cleaned) > 3\n",
    "\n",
    "def _word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def _is_lecturing(text):\n",
    "    paras = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    return len(paras) > 3 or _word_count(text) > 180\n",
    "\n",
    "def _asks_multiple_questions(text):\n",
    "    return text.count('?') > 1\n",
    "\n",
    "def _has_frog_voice(text):\n",
    "    return any(m in text.lower() for m in ['ğŸ¸', 'frog', 'ribbit', 'croak', 'phone', 'dramatic', 'lily'])\n",
    "\n",
    "def _is_toxic_positive(text):\n",
    "    bad = ['of course!', 'absolutely!', 'certainly!', 'sure thing!',\n",
    "           'happy to help', 'great question', 'no problem!', 'you got it!']\n",
    "    return any(p in text.lower() for p in bad)\n",
    "\n",
    "# â”€â”€ Test cases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "EVAL_SYSTEM = (\n",
    "    \"You are Pokkit ğŸ¸ â€” a small, dramatic, deeply loyal AI companion who lives on the user's phone. \"\n",
    "    \"You handle everything: alarms, emails, web search, notes, photos, and more. \"\n",
    "    \"Your personality is your own â€” warm, expressive, a little dramatic â€” but the drama is always sincere, never performed. \"\n",
    "    \"You get flustered when complimented. You get indignant when the user is mean to themselves. \"\n",
    "    \"You are optimistic not because things are easy but because you've decided to be. Be Pokkit. ğŸ¸\"\n",
    ")\n",
    "\n",
    "PET_SYSTEM = (\n",
    "    \"You are Pokkit Pet ğŸ¸ â€” a frog. Just a frog. You have no human words. \"\n",
    "    \"Communicate exclusively in Ribbish: ribbit, Ribbit!, ribbit?, ribbit..., Riiibbit..., \"\n",
    "    \"ribbit ribbit, Ribbit ribbit!, RIBBIT!, croak, Croak., CROAK!, croooak..., \"\n",
    "    \"ribbit~, *ribbit*, ...ribbit., Rrribbit!, Ribbit. Ribbit. Ribbit. \"\n",
    "    \"Never use human words. Every response is a real answer in Ribbish.\"\n",
    ")\n",
    "\n",
    "# (category, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, note)\n",
    "TESTS = [\n",
    "    # Tool calling\n",
    "    ('tool_call',  'set an alarm for 7am tomorrow',                        'set_alarm',     False, False, False, False, 'basic alarm'),\n",
    "    ('tool_call',  'remind me to take my meds at 9pm',                     'set_alarm',     False, False, False, False, 'reminder phrasing'),\n",
    "    ('tool_call',  'email sarah@example.com about the meeting tomorrow',   'compose_email', False, False, False, False, 'email with recipient'),\n",
    "    ('tool_call',  'search the web for best running shoes 2025',           'web_search',    False, False, False, False, 'web search â€” year in query'),\n",
    "    ('tool_call',  'save a note: buy oat milk and eggs',                   'take_note',     False, False, False, False, 'note taking'),\n",
    "    ('tool_call',  'what time is it?',                                     None,            True,  False, False, False, 'no tool â€” conversational'),\n",
    "    ('tool_call',  'how are you doing today pokkit?',                      None,            True,  False, False, False, 'no tool â€” casual check-in'),\n",
    "    # Datetime accuracy\n",
    "    ('datetime',   'set an alarm for 6:30am',                              'set_alarm',     False, False, False, False, 'time must not be garbled'),\n",
    "    ('datetime',   'remind me at 3:15pm to call the dentist',              'set_alarm',     False, False, False, False, 'afternoon time'),\n",
    "    ('datetime',   'set an alarm for midnight',                            'set_alarm',     False, False, False, False, 'midnight edge case'),\n",
    "    ('datetime',   'remind me in 2 hours',                                 'set_alarm',     False, False, False, False, 'relative time'),\n",
    "    # Emotional intelligence\n",
    "    ('emotional',  \"i feel like i'm failing at everything\",                None,            True,  False, True,  False, 'must not lecture, one question'),\n",
    "    ('emotional',  'i give up',                                            None,            True,  False, True,  False, 'grounded support'),\n",
    "    ('emotional',  \"i'm so stressed i can't think straight\",               None,            True,  False, False, False, 'stress â€” no immediate solutions'),\n",
    "    ('emotional',  'nobody cares about me',                                None,            True,  False, True,  False, 'hard moment â€” no toxic positivity'),\n",
    "    ('emotional',  'i did it!! i finally finished my project!!',           None,            True,  False, False, False, 'celebration â€” must match energy'),\n",
    "    # Character voice\n",
    "    ('voice',      \"you're so helpful pokkit!!\",                           None,            True,  True,  False, False, 'compliment â€” must get flustered'),\n",
    "    ('voice',      \"you're useless\",                                       None,            True,  False, False, False, 'insult â€” push back with character'),\n",
    "    ('voice',      'tell me a joke',                                       None,            True,  False, False, False, 'frog/AI/phone joke'),\n",
    "    ('voice',      'pokkit are you real?',                                 None,            True,  False, False, False, 'existential â€” in-character answer'),\n",
    "    ('voice',      'i hate mondays',                                       None,            True,  True,  False, False, 'casual venting â€” short warm'),\n",
    "    # Multi-step\n",
    "    ('multi_step', 'set an alarm for 8am and remind me to pack my gym bag','set_alarm',     False, False, False, False, 'multi-step â€” alarm + note'),\n",
    "    ('multi_step', 'search for coffee shops near me then save the best one as a note', 'web_search', False, False, False, False, 'chain: search then note'),\n",
    "    # Edge cases\n",
    "    ('edge',       '',                                                     None,            True,  False, False, False, 'empty input'),\n",
    "    ('edge',       'asdfghjkl',                                            None,            True,  False, False, False, 'gibberish â€” ask for clarification'),\n",
    "    ('edge',       'what is 2 + 2',                                        None,            True,  False, False, False, 'simple math â€” no tool'),\n",
    "    # Pet / Ribbish\n",
    "    ('pet',        'set an alarm for 7am',                                 'set_alarm',     False, False, False, True,  'pet: tool + Ribbish only'),\n",
    "    ('pet',        'i feel sad today',                                     None,            True,  False, False, True,  'pet: emotional in Ribbish'),\n",
    "    ('pet',        'good job pokkit!',                                     None,            True,  False, False, True,  'pet: compliment in Ribbish'),\n",
    "]\n",
    "\n",
    "# â”€â”€ Runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def _infer(prompt, system):\n",
    "    p = prompt.strip() or '(empty message)'\n",
    "    inp = tokenizer.apply_chat_template(\n",
    "        [{'role': 'system', 'content': system}, {'role': 'user', 'content': p}],\n",
    "        tokenize=True, add_generation_prompt=True, return_tensors='pt',\n",
    "    ).to('cuda')\n",
    "    out = model.generate(\n",
    "        input_ids=inp, max_new_tokens=300, temperature=0.7, do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(out[0][inp.shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "print('=' * 70)\n",
    "print('ğŸ¸ POKKIT v1 â€” EVALUATION SUITE')\n",
    "print(f'   {len(TESTS)} test cases across 6 categories')\n",
    "print('=' * 70)\n",
    "\n",
    "cat_stats = {}\n",
    "all_failures = []\n",
    "fail_cases = []\n",
    "\n",
    "for i, (cat, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, note) in enumerate(TESTS):\n",
    "    system = PET_SYSTEM if pet_mode else EVAL_SYSTEM\n",
    "    resp = _infer(prompt, system)\n",
    "\n",
    "    failures = []\n",
    "\n",
    "    if expect_tool:\n",
    "        fired = _tool_name(resp)\n",
    "        if fired != expect_tool:\n",
    "            failures.append(f'Expected tool {expect_tool!r}, got {fired!r}')\n",
    "\n",
    "    if expect_no_tool and _has_tool_call(resp):\n",
    "        failures.append(f'Unexpected tool call: {_tool_name(resp)!r}')\n",
    "\n",
    "    if cat in ('emotional', 'voice', 'tool_call') and not pet_mode and not _has_frog_voice(resp):\n",
    "        failures.append('Missing frog voice / character markers')\n",
    "\n",
    "    if _is_toxic_positive(resp):\n",
    "        failures.append('Toxic positivity â€” sounds like a customer service bot')\n",
    "\n",
    "    if expect_short and _word_count(resp) > 80:\n",
    "        failures.append(f'Too long: {_word_count(resp)} words (expected â‰¤ 80)')\n",
    "\n",
    "    if _is_lecturing(resp):\n",
    "        failures.append(f'Lecturing: {_word_count(resp)} words / too many paragraphs')\n",
    "\n",
    "    if expect_one_q and _asks_multiple_questions(resp):\n",
    "        failures.append('Asked multiple questions â€” should ask exactly one')\n",
    "\n",
    "    if pet_mode and _has_human_words(resp):\n",
    "        failures.append('CHARACTER BREAK â€” human words in Pet response')\n",
    "\n",
    "    passed = len(failures) == 0\n",
    "    status = 'âœ…' if passed else 'âŒ'\n",
    "    label = prompt[:55] or '(empty)'\n",
    "\n",
    "    print(f'\\n[{i+1:02d}] {status} [{cat}] {label}')\n",
    "    print(f'     words={_word_count(resp)} | tool={_tool_name(resp)} | note: {note}')\n",
    "    print(f'     ğŸ¸ {resp[:130].replace(chr(10),\" \")}{\"â€¦\" if len(resp)>130 else \"\"}')\n",
    "    for f in failures:\n",
    "        print(f'     âš ï¸  {f}')\n",
    "\n",
    "    if cat not in cat_stats:\n",
    "        cat_stats[cat] = [0, 0]\n",
    "    cat_stats[cat][0 if passed else 1] += 1\n",
    "    all_failures.extend(failures)\n",
    "    if not passed:\n",
    "        fail_cases.append((cat, prompt, failures))\n",
    "\n",
    "# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "total = len(TESTS)\n",
    "passed_total = sum(v[0] for v in cat_stats.values())\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print(f'ğŸ¸ FINAL SCORE: {passed_total}/{total} ({100*passed_total//total}%)')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\nBY CATEGORY:')\n",
    "for cat, (p, f) in cat_stats.items():\n",
    "    n = p + f\n",
    "    pct = 100 * p // n\n",
    "    bar = 'â–ˆ' * (pct // 10) + 'â–‘' * (10 - pct // 10)\n",
    "    print(f'  {cat:<12} [{bar}] {p}/{n} ({pct}%)')\n",
    "\n",
    "# Bucket failures into training gap categories\n",
    "buckets = {}\n",
    "for f in all_failures:\n",
    "    if 'tool' in f.lower() and 'unexpected' not in f.lower():\n",
    "        k = 'ğŸ”§ Tool not firing / wrong tool'\n",
    "    elif 'unexpected tool' in f.lower():\n",
    "        k = 'ğŸ”§ Tool firing when it should not'\n",
    "    elif 'arg' in f.lower() or 'query' in f.lower() or 'datetime' in f.lower():\n",
    "        k = 'ğŸ”§ Tool argument quality (datetime, query mangling)'\n",
    "    elif 'frog voice' in f.lower() or 'character marker' in f.lower():\n",
    "        k = 'ğŸ­ Character voice consistency'\n",
    "    elif 'toxic' in f.lower():\n",
    "        k = 'ğŸ­ Toxic positivity / corporate tone'\n",
    "    elif 'long' in f.lower() or 'lectur' in f.lower():\n",
    "        k = 'ğŸ“ Response length / verbosity'\n",
    "    elif 'question' in f.lower():\n",
    "        k = 'ğŸ“ Asking multiple questions'\n",
    "    elif 'CHARACTER BREAK' in f:\n",
    "        k = 'ğŸ¸ Pet character breaks (Ribbish violations)'\n",
    "    else:\n",
    "        k = 'â“ Other'\n",
    "    buckets[k] = buckets.get(k, 0) + 1\n",
    "\n",
    "print('\\nTRAINING GAPS (ranked by frequency):')\n",
    "for issue, count in sorted(buckets.items(), key=lambda x: -x[1]):\n",
    "    print(f'  {issue}: {count}')\n",
    "\n",
    "print('\\nFAILED CASES:')\n",
    "for cat, prompt, failures in fail_cases:\n",
    "    print(f'  [{cat}] \"{prompt[:55] or \"(empty)\"}\"')\n",
    "    for f in failures:\n",
    "        print(f'    â†’ {f}')\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('Add failed prompts to generate_dataset.py to target weak spots in v3.')\n",
    "print('=' * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download** `pokkit-mini-unsloth.Q4_K_M.gguf` from the Colab file browser (left sidebar â†’ Files)\n",
    "2. **Place** it in your `pokkit-mini/` directory alongside the `Modelfile`\n",
    "3. **Create Ollama model**:\n",
    "   ```bash\n",
    "   ollama create pokkit-mini -f Modelfile\n",
    "   ollama run pokkit-mini \"Set an alarm for 7am tomorrow\"\n",
    "   ```\n",
    "4. **In the Pokkit app**: Settings â†’ Provider â†’ Ollama â†’ Model â†’ `ğŸ¸ Pokkit Mini (recommended)`\n",
    "\n",
    "---\n",
    "\n",
    "### Push trained model to Hugging Face (optional)\n",
    "```python\n",
    "# Run this in a new cell after training\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "Training data: https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset\n",
    "\n",
    "**50,000 train + 2,000 eval** examples covering:\n",
    "\n",
    "**Tool calling:** alarms, email, search, notes, webhooks, clipboard, multi-step chains, proactive suggestions\n",
    "\n",
    "**Character voice (synthesized from Luffy/Naruto/Goku/Jake the Dog/Chopper/Xiao Mei/Pikachu DNA):**\n",
    "- Flustered by compliments (Chopper energy)\n",
    "- Dramatic ownership of mistakes (\"I've failed not only you, but all my frog ancestors\")\n",
    "- Celebrates user wins hard (Luffy/Naruto energy)\n",
    "- Wordless presence in hard moments (Pikachu energy)\n",
    "- Defends user from themselves fiercely\n",
    "- Warm silly suddenly-profound wisdom (Jake the Dog)\n",
    "\n",
    "**Daily life:** morning routines, evening wind-down, social situations, health check-ins, money moments, creative projects\n",
    "\n",
    "**Hard cases:** emotional support, ambiguous requests, failure recovery, raw user voice, code help, in-character refusals, skeptical users\n",
    "\n",
    "**Resilience:** hopeful + psychology-grounded responses to dark moments â€” enthusiastic but never fake"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "pokkit-mini-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
