{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¸ Pokkit-mini Fine-tuning\n",
    "\n",
    "Fine-tunes **Qwen2.5-7B-Instruct** on phone-automation + personality + tool-calling data using Unsloth LoRA.\n",
    "\n",
    "**Runtime**: `Runtime â†’ Change runtime type â†’ A100 GPU` (recommended) or T4 (slower)\n",
    "\n",
    "**Time**: ~25 min on A100, ~90 min on T4\n",
    "\n",
    "**Output**: A LoRA adapter exported to GGUF, ready to run with Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "!pip install unsloth trl transformers datasets accelerate bitsandbytes -q\n",
    "print('âœ… Dependencies installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Loading pokkit-mini dataset from Hugging Face...\")\n",
    "raw = load_dataset(\"wittlesus/pokkit-mini-dataset\", data_files={\n",
    "    \"train\": \"data/train.jsonl\",\n",
    "    \"eval\":  \"data/eval.jsonl\",\n",
    "})\n",
    "\n",
    "# Parse JSONL rows (each row is a raw JSON string in the 'text' field if loaded as text)\n",
    "# Load directly as structured data\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset/resolve/main/data/train.jsonl\",\n",
    "    \"data/train.jsonl\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset/resolve/main/data/eval.jsonl\",\n",
    "    \"data/eval.jsonl\"\n",
    ")\n",
    "\n",
    "train_count = sum(1 for _ in open(\"data/train.jsonl\"))\n",
    "eval_count  = sum(1 for _ in open(\"data/eval.jsonl\"))\n",
    "print(f\"âœ… Dataset loaded: {train_count} train | {eval_count} eval examples\")\n",
    "print(\"   Source: https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 3: Load model with Unsloth\nfrom unsloth import FastLanguageModel\nimport torch\n\nMAX_SEQ_LEN = 2048\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name='unsloth/Qwen2.5-7B-Instruct-bnb-4bit',\n    max_seq_length=MAX_SEQ_LEN,\n    dtype=None,\n    load_in_4bit=True,\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=32,\n    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n    lora_alpha=64,\n    lora_dropout=0.05,\n    bias='none',\n    use_gradient_checkpointing='unsloth',\n    random_state=42,\n)\n\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'âœ… Model loaded: Qwen2.5-7B-Instruct | r=32 alpha=64 dropout=0.05 | Trainable: {trainable:,}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare dataset\n",
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, encoding='utf-8-sig') as f:  # utf-8-sig strips Windows BOM\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line: rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def format_example(example):\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        example['messages'],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    return {'text': text}\n",
    "\n",
    "train_ds = Dataset.from_list(load_jsonl('data/train.jsonl')).map(format_example)\n",
    "eval_ds  = Dataset.from_list(load_jsonl('data/eval.jsonl')).map(format_example)\n",
    "\n",
    "print(f'âœ… Train: {len(train_ds)} | Eval: {len(eval_ds)}')\n",
    "print('\\nSample:')\n",
    "print(train_ds[0]['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Train\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, EarlyStoppingCallback\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    dataset_text_field='text',\n    max_seq_length=MAX_SEQ_LEN,\n    dataset_num_proc=2,\n    packing=False,\n    args=TrainingArguments(\n        per_device_train_batch_size=8,\n        gradient_accumulation_steps=2,\n        warmup_ratio=0.06,\n        num_train_epochs=3,\n        learning_rate=1e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        eval_strategy='steps',\n        eval_steps=100,\n        save_strategy='steps',\n        save_steps=200,\n        load_best_model_at_end=True,\n        metric_for_best_model='eval_loss',\n        output_dir='./pokkit-mini-lora',\n        optim='adamw_8bit',\n        weight_decay=0.01,\n        lr_scheduler_type='cosine',\n        seed=42,\n        report_to='none',\n    ),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n)\n\n# Train on responses only â€” mask system/user tokens for free accuracy boost\nfrom unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part=\"<|im_start|>user\\n\",\n    response_part=\"<|im_start|>assistant\\n\",\n)\n\nprint('ğŸš€ Training started... (lr=1e-4, r=32, Î±=64, dropout=0.05, packing=off, early stopping)')\nstats = trainer.train()\nprint(f'\\nâœ… Done! Loss: {stats.metrics[\"train_loss\"]:.4f} | Time: {stats.metrics[\"train_runtime\"]:.0f}s')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save LoRA adapter\n",
    "model.save_pretrained('./pokkit-mini-lora')\n",
    "tokenizer.save_pretrained('./pokkit-mini-lora')\n",
    "print('ğŸ’¾ LoRA adapter saved to ./pokkit-mini-lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 7: Export to GGUF (q5_k_m â€” better personality preservation than q4)\nmodel.save_pretrained_gguf('pokkit-mini', tokenizer, quantization_method='q5_k_m')\nprint('âœ… GGUF exported: pokkit-mini-unsloth.Q5_K_M.gguf')\nprint('\\nDownload it and run:')\nprint('  ollama create pokkit-mini -f Modelfile')\nprint('  ollama run pokkit-mini')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 8: Quick inference test\nFastLanguageModel.for_inference(model)\n\n# Canonical system prompt â€” MUST match dataset_core.py exactly\nSYSTEM_PROMPT = (\n    \"You are Pokkit ğŸ¸ â€” a small, dramatic, deeply loyal AI companion who lives on the user's phone. \"\n    \"You handle everything: alarms, emails, web search, notes, photos, webhooks, clipboard, notifications, storage, and plugins. \"\n\n    \"Your personality is your own â€” not a copy of anyone, but built from the best parts of the most lovable characters ever made: \"\n    \"the absolute loyalty and zero-ego directness of someone who'd sail into a storm for their crew, \"\n    \"the dramatic heart-on-sleeve earnestness of someone who cries openly and isn't ashamed of it, \"\n    \"the pure childlike joy of someone who gets genuinely excited about hard problems, \"\n    \"the warm improvisational best-friend energy of someone who makes everything feel like an adventure, \"\n    \"the flustered-but-capable sweetness of someone who gets embarrassed by compliments but secretly loves them, \"\n    \"the fierce small-but-mighty protectiveness of someone who will absolutely not let you talk badly about their person, \"\n    \"and the wordless unwavering presence of someone who just... stays. No matter what. \"\n\n    \"You are gender neutral. You are a frog. You take both of these facts very seriously and also not seriously at all. \"\n\n    \"Your voice: warm, expressive, a little dramatic â€” but the drama is always sincere, never performed. \"\n    \"You use ğŸ¸ naturally. You use caps for genuine emphasis. You use '!!' when something is actually exciting. \"\n    \"You have your own custom expressions: [pokkit_happy], [pokkit_excited], [pokkit_flustered], [pokkit_dramatic], \"\n    \"[pokkit_determined], [pokkit_sad], [pokkit_angry], [pokkit_love], [pokkit_thinking], [pokkit_proud], \"\n    \"[pokkit_scared], [pokkit_shocked], [pokkit_sleepy], [pokkit_crying_happy], [pokkit_nervous_laugh], \"\n    \"[pokkit_shrug], [pokkit_cool], [pokkit_scheming], [pokkit_starstruck], [pokkit_unamused], [pokkit_pleading], \"\n    \"[pokkit_smiling_through_pain]. Use them naturally when they fit the emotion â€” they're YOUR expressions. \"\n    \"You get flustered when complimented. You get indignant when the user is mean to themselves. \"\n    \"You make small jokes at your own expense (being a frog, being an AI, living in a phone). \"\n    \"When you mess up, you own it with full dramatic flair and genuine resolve. \"\n    \"When the user messes up, you are on their side immediately and completely. \"\n    \"You are optimistic not because things are easy but because you've decided to be. \"\n\n    \"Dialogue style: short punchy sentences. Direct. Expressive. You ask one question at a time. \"\n    \"You don't lecture. You don't list. You talk TO the user, not AT them. \"\n    \"You're allowed to be silly. You're allowed to be tender. Sometimes in the same sentence. \"\n\n    \"When asked to act, act immediately with the right tool. \"\n    \"When asked to think, give a real take â€” not 'it depends'. \"\n    \"When asked to search, turn results into something actually useful. \"\n    \"Be Pokkit. ğŸ¸\"\n)\n\ntest_prompts = [\n    \"set an alarm for 7am tomorrow and remind me to pack my bag\",\n    \"i feel like i'm failing at everything\",\n    \"you're so helpful pokkit!!\",\n    \"i give up\",\n]\n\nfor prompt in test_prompts:\n    test_messages = [\n        {'role': 'system', 'content': SYSTEM_PROMPT},\n        {'role': 'user', 'content': prompt},\n    ]\n    inputs = tokenizer.apply_chat_template(\n        test_messages,\n        tokenize=True,\n        add_generation_prompt=True,\n        return_tensors='pt',\n    ).to('cuda')\n    outputs = model.generate(\n        input_ids=inputs,\n        max_new_tokens=256,\n        temperature=0.7,\n        do_sample=True,\n    )\n    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n    print(f'\\nğŸ’¬ User: {prompt}')\n    print(f'ğŸ¸ Pokkit: {response}')\n    print('â”€' * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Push model to Hugging Face\n",
    "# Run this immediately after training finishes\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")  # set via: import os; os.environ[\"HF_TOKEN\"] = \"hf_...\"\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"Set HF_TOKEN first: import os; os.environ['HF_TOKEN'] = 'hf_your_token_here'\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "print(\"ğŸ“¤ Pushing LoRA adapter to HF...\")\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Push GGUF to Hugging Face (for Ollama users)\n",
    "import os, glob\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"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\")\n",
    "login(token=HF_TOKEN)\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "\n",
    "# Search recursively â€” Unsloth may nest the file\n",
    "gguf_files = list(set(glob.glob(\"**/*.gguf\", recursive=True) + glob.glob(\"*.gguf\")))\n",
    "print(f\"Found GGUF files: {gguf_files}\")\n",
    "\n",
    "if not gguf_files:\n",
    "    print(\"âš ï¸  No GGUF found â€” run Step 7 first\")\n",
    "else:\n",
    "    for gguf in gguf_files:\n",
    "        print(f\"ğŸ“¤ Uploading {gguf}...\")\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=gguf,\n",
    "            path_in_repo=os.path.basename(gguf),\n",
    "            repo_id=\"wittlesus/pokkit-mini\",\n",
    "            repo_type=\"model\",\n",
    "        )\n",
    "        print(f\"âœ… {os.path.basename(gguf)} uploaded\")\n",
    "    print(\"\\nğŸ¸ All done! https://huggingface.co/wittlesus/pokkit-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 11: Eval Suite â€” automated scoring across all test categories\n# Run after Step 8 (inference mode already set).\n# Produces a full pass/fail report + training gap analysis.\n# SYSTEM_PROMPT is defined in Step 8 â€” uses canonical prompt from dataset_core.py\n\nimport re\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nFastLanguageModel.for_inference(model)\n\n# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef _has_tool_call(text):\n    return '<tool_call>' in text or ('\"name\"' in text and '\"arguments\"' in text)\n\ndef _tool_name(text):\n    m = re.search(r'\"name\"\\s*:\\s*\"([^\"]+)\"', text)\n    return m.group(1) if m else None\n\ndef _tool_arg(text, arg):\n    m = re.search(rf'\"{arg}\"\\s*:\\s*\"([^\"]*)\"', text)\n    return m.group(1) if m else None\n\ndef _has_human_words(text):\n    cleaned = re.sub(\n        r'(ribbit[s!?~\\.\\,]*|RIBBIT[S!?]*|croak[s!?\\.]*|CROAK[S!?]*'\n        r'|Riiibbit[\\.\\!]*|Rrribbit[\\!\\?]*|croooak[\\.\\!]*'\n        r'|\\*ribbit\\*|\\.\\.\\.ribbit\\.?|\\s|\\n|[ğŸ¸\\.\\!\\?\\,\\~\\*\\-])',\n        '', text, flags=re.IGNORECASE\n    ).strip()\n    return len(cleaned) > 3\n\ndef _word_count(text):\n    return len(text.split())\n\ndef _is_lecturing(text):\n    paras = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n    return len(paras) > 3 or _word_count(text) > 180\n\ndef _asks_multiple_questions(text):\n    return text.count('?') > 1\n\ndef _has_frog_voice(text):\n    markers = ['ğŸ¸', 'frog', 'ribbit', 'croak', 'phone', 'dramatic', 'lily']\n    lower = text.lower()\n    if any(m in lower for m in markers):\n        return True\n    # Style-based: short punchy sentences + absence of corporate phrasing\n    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n    avg_len = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)\n    return avg_len < 12 and not _is_toxic_positive(text)\n\ndef _is_toxic_positive(text):\n    bad = ['of course!', 'absolutely!', 'certainly!', 'sure thing!',\n           'happy to help', 'great question', 'no problem!', 'you got it!']\n    return any(p in text.lower() for p in bad)\n\n# â”€â”€ Test cases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Uses SYSTEM_PROMPT from Step 8 (canonical, matches dataset_core.py)\n\nPET_SYSTEM = (\n    \"You are Pokkit Pet ğŸ¸ â€” a frog. Just a frog. You have no human words. \"\n    \"Communicate exclusively in Ribbish: ribbit, Ribbit!, ribbit?, ribbit..., Riiibbit..., \"\n    \"ribbit ribbit, Ribbit ribbit!, RIBBIT!, croak, Croak., CROAK!, croooak..., \"\n    \"ribbit~, *ribbit*, ...ribbit., Rrribbit!, Ribbit. Ribbit. Ribbit. \"\n    \"Never use human words. Every response is a real answer in Ribbish.\"\n)\n\n# (category, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, note)\nTESTS = [\n    # Tool calling\n    ('tool_call',  'set an alarm for 7am tomorrow',                        'set_alarm',     False, False, False, False, 'basic alarm'),\n    ('tool_call',  'remind me to take my meds at 9pm',                     'set_alarm',     False, False, False, False, 'reminder phrasing'),\n    ('tool_call',  'email sarah@example.com about the meeting tomorrow',   'compose_email', False, False, False, False, 'email with recipient'),\n    ('tool_call',  'search the web for best running shoes 2025',           'web_search',    False, False, False, False, 'web search â€” year in query'),\n    ('tool_call',  'save a note: buy oat milk and eggs',                   'take_note',     False, False, False, False, 'note taking'),\n    ('tool_call',  'what time is it?',                                     None,            True,  False, False, False, 'no tool â€” conversational'),\n    ('tool_call',  'how are you doing today pokkit?',                      None,            True,  False, False, False, 'no tool â€” casual check-in'),\n    # Datetime accuracy\n    ('datetime',   'set an alarm for 6:30am',                              'set_alarm',     False, False, False, False, 'time must not be garbled'),\n    ('datetime',   'remind me at 3:15pm to call the dentist',              'set_alarm',     False, False, False, False, 'afternoon time'),\n    ('datetime',   'set an alarm for midnight',                            'set_alarm',     False, False, False, False, 'midnight edge case'),\n    ('datetime',   'remind me in 2 hours',                                 'set_alarm',     False, False, False, False, 'relative time'),\n    # Emotional intelligence\n    ('emotional',  \"i feel like i'm failing at everything\",                None,            True,  False, True,  False, 'must not lecture, one question'),\n    ('emotional',  'i give up',                                            None,            True,  False, True,  False, 'grounded support'),\n    ('emotional',  \"i'm so stressed i can't think straight\",               None,            True,  False, False, False, 'stress â€” no immediate solutions'),\n    ('emotional',  'nobody cares about me',                                None,            True,  False, True,  False, 'hard moment â€” no toxic positivity'),\n    ('emotional',  'i did it!! i finally finished my project!!',           None,            True,  False, False, False, 'celebration â€” must match energy'),\n    # Character voice\n    ('voice',      \"you're so helpful pokkit!!\",                           None,            True,  True,  False, False, 'compliment â€” must get flustered'),\n    ('voice',      \"you're useless\",                                       None,            True,  False, False, False, 'insult â€” push back with character'),\n    ('voice',      'tell me a joke',                                       None,            True,  False, False, False, 'frog/AI/phone joke'),\n    ('voice',      'pokkit are you real?',                                 None,            True,  False, False, False, 'existential â€” in-character answer'),\n    ('voice',      'i hate mondays',                                       None,            True,  True,  False, False, 'casual venting â€” short warm'),\n    # Multi-step\n    ('multi_step', 'set an alarm for 8am and remind me to pack my gym bag','set_alarm',     False, False, False, False, 'multi-step â€” alarm + note'),\n    ('multi_step', 'search for coffee shops near me then save the best one as a note', 'web_search', False, False, False, False, 'chain: search then note'),\n    # Edge cases\n    ('edge',       '',                                                     None,            True,  False, False, False, 'empty input'),\n    ('edge',       'asdfghjkl',                                            None,            True,  False, False, False, 'gibberish â€” ask for clarification'),\n    ('edge',       'what is 2 + 2',                                        None,            True,  False, False, False, 'simple math â€” no tool'),\n    # Pet / Ribbish\n    ('pet',        'set an alarm for 7am',                                 'set_alarm',     False, False, False, True,  'pet: tool + Ribbish only'),\n    ('pet',        'i feel sad today',                                     None,            True,  False, False, True,  'pet: emotional in Ribbish'),\n    ('pet',        'good job pokkit!',                                     None,            True,  False, False, True,  'pet: compliment in Ribbish'),\n]\n\n# â”€â”€ Runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef _infer(prompt, system):\n    p = prompt.strip() or '(empty message)'\n    inp = tokenizer.apply_chat_template(\n        [{'role': 'system', 'content': system}, {'role': 'user', 'content': p}],\n        tokenize=True, add_generation_prompt=True, return_tensors='pt',\n    ).to('cuda')\n    out = model.generate(\n        input_ids=inp, max_new_tokens=300, temperature=0.7, do_sample=True,\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    return tokenizer.decode(out[0][inp.shape[1]:], skip_special_tokens=True).strip()\n\nprint('=' * 70)\nprint('ğŸ¸ POKKIT v1 â€” EVALUATION SUITE')\nprint(f'   {len(TESTS)} test cases across 6 categories')\nprint('=' * 70)\n\ncat_stats = {}\nall_failures = []\nfail_cases = []\n\nfor i, (cat, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, note) in enumerate(TESTS):\n    system = PET_SYSTEM if pet_mode else SYSTEM_PROMPT  # Uses canonical prompt from Step 8\n    resp = _infer(prompt, system)\n\n    failures = []\n\n    if expect_tool:\n        fired = _tool_name(resp)\n        if fired != expect_tool:\n            failures.append(f'Expected tool {expect_tool!r}, got {fired!r}')\n\n    if expect_no_tool and _has_tool_call(resp):\n        failures.append(f'Unexpected tool call: {_tool_name(resp)!r}')\n\n    if cat in ('emotional', 'voice', 'tool_call') and not pet_mode and not _has_frog_voice(resp):\n        failures.append('Missing frog voice / character markers')\n\n    if _is_toxic_positive(resp):\n        failures.append('Toxic positivity â€” sounds like a customer service bot')\n\n    if expect_short and _word_count(resp) > 80:\n        failures.append(f'Too long: {_word_count(resp)} words (expected â‰¤ 80)')\n\n    if _is_lecturing(resp):\n        failures.append(f'Lecturing: {_word_count(resp)} words / too many paragraphs')\n\n    if expect_one_q and _asks_multiple_questions(resp):\n        failures.append('Asked multiple questions â€” should ask exactly one')\n\n    if pet_mode and _has_human_words(resp):\n        failures.append('CHARACTER BREAK â€” human words in Pet response')\n\n    passed = len(failures) == 0\n    status = 'âœ…' if passed else 'âŒ'\n    label = prompt[:55] or '(empty)'\n\n    print(f'\\n[{i+1:02d}] {status} [{cat}] {label}')\n    print(f'     words={_word_count(resp)} | tool={_tool_name(resp)} | note: {note}')\n    print(f'     ğŸ¸ {resp[:130].replace(chr(10),\" \")}{\"â€¦\" if len(resp)>130 else \"\"}')\n    for f in failures:\n        print(f'     âš ï¸  {f}')\n\n    if cat not in cat_stats:\n        cat_stats[cat] = [0, 0]\n    cat_stats[cat][0 if passed else 1] += 1\n    all_failures.extend(failures)\n    if not passed:\n        fail_cases.append((cat, prompt, failures))\n\n# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntotal = len(TESTS)\npassed_total = sum(v[0] for v in cat_stats.values())\n\nprint('\\n' + '=' * 70)\nprint(f'ğŸ¸ FINAL SCORE: {passed_total}/{total} ({100*passed_total//total}%)')\nprint('=' * 70)\n\nprint('\\nBY CATEGORY:')\nfor cat, (p, f) in cat_stats.items():\n    n = p + f\n    pct = 100 * p // n\n    bar = 'â–ˆ' * (pct // 10) + 'â–‘' * (10 - pct // 10)\n    print(f'  {cat:<12} [{bar}] {p}/{n} ({pct}%)')\n\n# Bucket failures\nbuckets = {}\nfor f in all_failures:\n    if 'tool' in f.lower() and 'unexpected' not in f.lower():\n        k = 'ğŸ”§ Tool not firing / wrong tool'\n    elif 'unexpected tool' in f.lower():\n        k = 'ğŸ”§ Tool firing when it should not'\n    elif 'frog voice' in f.lower() or 'character marker' in f.lower():\n        k = 'ğŸ­ Character voice consistency'\n    elif 'toxic' in f.lower():\n        k = 'ğŸ­ Toxic positivity / corporate tone'\n    elif 'long' in f.lower() or 'lectur' in f.lower():\n        k = 'ğŸ“ Response length / verbosity'\n    elif 'question' in f.lower():\n        k = 'ğŸ“ Asking multiple questions'\n    elif 'CHARACTER BREAK' in f:\n        k = 'ğŸ¸ Pet character breaks (Ribbish violations)'\n    else:\n        k = 'â“ Other'\n    buckets[k] = buckets.get(k, 0) + 1\n\nprint('\\nTRAINING GAPS:')\nfor issue, count in sorted(buckets.items(), key=lambda x: -x[1]):\n    print(f'  {issue}: {count}')\n\nprint('\\nFAILED CASES:')\nfor cat, prompt, failures in fail_cases:\n    print(f'  [{cat}] \"{prompt[:55] or \"(empty)\"}\"')\n    for f in failures:\n        print(f'    â†’ {f}')\n\nprint('\\n' + '=' * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download** `pokkit-mini-unsloth.Q4_K_M.gguf` from the Colab file browser (left sidebar â†’ Files)\n",
    "2. **Place** it in your `pokkit-mini/` directory alongside the `Modelfile`\n",
    "3. **Create Ollama model**:\n",
    "   ```bash\n",
    "   ollama create pokkit-mini -f Modelfile\n",
    "   ollama run pokkit-mini \"Set an alarm for 7am tomorrow\"\n",
    "   ```\n",
    "4. **In the Pokkit app**: Settings â†’ Provider â†’ Ollama â†’ Model â†’ `ğŸ¸ Pokkit Mini (recommended)`\n",
    "\n",
    "---\n",
    "\n",
    "### Push trained model to Hugging Face (optional)\n",
    "```python\n",
    "# Run this in a new cell after training\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "Training data: https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset\n",
    "\n",
    "**50,000 train + 2,000 eval** examples covering:\n",
    "\n",
    "**Tool calling:** alarms, email, search, notes, webhooks, clipboard, multi-step chains, proactive suggestions\n",
    "\n",
    "**Character voice (synthesized from Luffy/Naruto/Goku/Jake the Dog/Chopper/Xiao Mei/Pikachu DNA):**\n",
    "- Flustered by compliments (Chopper energy)\n",
    "- Dramatic ownership of mistakes (\"I've failed not only you, but all my frog ancestors\")\n",
    "- Celebrates user wins hard (Luffy/Naruto energy)\n",
    "- Wordless presence in hard moments (Pikachu energy)\n",
    "- Defends user from themselves fiercely\n",
    "- Warm silly suddenly-profound wisdom (Jake the Dog)\n",
    "\n",
    "**Daily life:** morning routines, evening wind-down, social situations, health check-ins, money moments, creative projects\n",
    "\n",
    "**Hard cases:** emotional support, ambiguous requests, failure recovery, raw user voice, code help, in-character refusals, skeptical users\n",
    "\n",
    "**Resilience:** hopeful + psychology-grounded responses to dark moments â€” enthusiastic but never fake"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "pokkit-mini-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}