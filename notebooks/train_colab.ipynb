{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¸ Pokkit-mini Fine-tuning\n",
    "\n",
    "Fine-tunes **Qwen2.5-7B-Instruct** on phone-automation + personality + tool-calling data using Unsloth LoRA.\n",
    "\n",
    "**Runtime**: `Runtime â†’ Change runtime type â†’ A100 GPU` (recommended) or T4 (slower)\n",
    "\n",
    "**Time**: ~25 min on A100, ~90 min on T4\n",
    "\n",
    "**Output**: A LoRA adapter exported to GGUF, ready to run with Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "!pip install unsloth trl transformers datasets accelerate bitsandbytes -q\n",
    "print('âœ… Dependencies installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 2: Download dataset from GitHub Release\nfrom pathlib import Path\nimport urllib.request\n\nPath(\"data\").mkdir(exist_ok=True)\n\nDATASET_URL = \"https://github.com/Wittlesus/pokkit-mini/releases/download/dataset-v6/train_v6.jsonl\"\nprint(\"Downloading pokkit-mini v6 dataset...\")\nurllib.request.urlretrieve(DATASET_URL, \"data/train.jsonl\")\n\ntrain_count = sum(1 for _ in open(\"data/train.jsonl\", encoding=\"utf-8\"))\nprint(f\"âœ… Dataset downloaded: {train_count} examples\")\nprint(\"   Source: https://github.com/Wittlesus/pokkit-mini/releases/tag/dataset-v6\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 3: Load model with Unsloth\nfrom unsloth import FastLanguageModel\nimport torch\n\nMAX_SEQ_LEN = 2048\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name='unsloth/Qwen2.5-7B-Instruct-bnb-4bit',\n    max_seq_length=MAX_SEQ_LEN,\n    dtype=None,\n    load_in_4bit=True,\n)\n\n# Add custom Pokkit emoji tokens so each is a single token (not 4-8 subwords)\nPOKKIT_EMOJI_TOKENS = [\n    \"[pokkit_happy]\", \"[pokkit_excited]\", \"[pokkit_flustered]\", \"[pokkit_dramatic]\",\n    \"[pokkit_determined]\", \"[pokkit_sad]\", \"[pokkit_angry]\", \"[pokkit_love]\",\n    \"[pokkit_thinking]\", \"[pokkit_proud]\", \"[pokkit_scared]\", \"[pokkit_shocked]\",\n    \"[pokkit_sleepy]\", \"[pokkit_crying_happy]\", \"[pokkit_nervous_laugh]\",\n    \"[pokkit_shrug]\", \"[pokkit_cool]\", \"[pokkit_scheming]\", \"[pokkit_starstruck]\",\n    \"[pokkit_unamused]\", \"[pokkit_pleading]\", \"[pokkit_smiling_through_pain]\",\n    \"[pokkit_phone]\", \"[pokkit_default]\",\n]\nnum_added = tokenizer.add_tokens(POKKIT_EMOJI_TOKENS)\nmodel.resize_token_embeddings(len(tokenizer))\nprint(f\"   Added {num_added} custom emoji tokens to tokenizer\")\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=32,\n    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n    lora_alpha=64,\n    lora_dropout=0.05,\n    bias='none',\n    use_gradient_checkpointing='unsloth',\n    random_state=42,\n)\n\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'âœ… Model loaded: Qwen2.5-7B-Instruct | r=32 alpha=64 dropout=0.05 | Trainable: {trainable:,}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 4: Prepare dataset\nimport json\nfrom datasets import Dataset\n\ndef load_jsonl(path):\n    rows = []\n    with open(path, encoding='utf-8-sig') as f:  # utf-8-sig strips Windows BOM\n        for line in f:\n            line = line.strip()\n            if line: rows.append(json.loads(line))\n    return rows\n\ndef format_example(example):\n    tools = example.get('tools', None)\n    text = tokenizer.apply_chat_template(\n        example['messages'],\n        tools=tools,\n        tokenize=False,\n        add_generation_prompt=False,\n    )\n    return {'text': text}\n\nall_data = load_jsonl('data/train.jsonl')\n\n# Split 90/10 for train/eval\nimport random\nrandom.seed(42)\nrandom.shuffle(all_data)\nsplit = int(len(all_data) * 0.9)\ntrain_raw, eval_raw = all_data[:split], all_data[split:]\n\ntrain_ds = Dataset.from_list(train_raw).map(format_example)\neval_ds  = Dataset.from_list(eval_raw).map(format_example)\n\nprint(f'âœ… Train: {len(train_ds)} | Eval: {len(eval_ds)} (90/10 split)')\nprint('\\nSample:')\nprint(train_ds[0]['text'][:300])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Train\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, EarlyStoppingCallback\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    dataset_text_field='text',\n    max_seq_length=MAX_SEQ_LEN,\n    dataset_num_proc=2,\n    packing=False,\n    args=TrainingArguments(\n        per_device_train_batch_size=8,\n        gradient_accumulation_steps=2,\n        warmup_ratio=0.06,\n        num_train_epochs=3,\n        learning_rate=5e-5,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        eval_strategy='steps',\n        eval_steps=100,\n        save_strategy='steps',\n        save_steps=200,\n        load_best_model_at_end=True,\n        metric_for_best_model='eval_loss',\n        output_dir='./pokkit-mini-lora',\n        optim='adamw_8bit',\n        weight_decay=0.01,\n        lr_scheduler_type='cosine',\n        seed=42,\n        report_to='none',\n    ),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n)\n\n# Train on responses only â€” mask system/user tokens for free accuracy boost\nfrom unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part=\"<|im_start|>user\\n\",\n    response_part=\"<|im_start|>assistant\\n\",\n)\n\nprint('ğŸš€ Training started... (lr=5e-5, r=32, Î±=64, dropout=0.05, packing=off, early stopping)')\nstats = trainer.train()\nprint(f'\\nâœ… Done! Loss: {stats.metrics[\"train_loss\"]:.4f} | Time: {stats.metrics[\"train_runtime\"]:.0f}s')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save LoRA adapter\n",
    "model.save_pretrained('./pokkit-mini-lora')\n",
    "tokenizer.save_pretrained('./pokkit-mini-lora')\n",
    "print('ğŸ’¾ LoRA adapter saved to ./pokkit-mini-lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 7: Export to GGUF (q5_k_m â€” better personality preservation than q4)\nmodel.save_pretrained_gguf('pokkit-mini', tokenizer, quantization_method='q5_k_m')\nprint('âœ… GGUF exported: pokkit-mini-unsloth.Q5_K_M.gguf')\nprint('\\nDownload it and run:')\nprint('  ollama create pokkit-mini -f Modelfile')\nprint('  ollama run pokkit-mini')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 8: Quick inference test\nFastLanguageModel.for_inference(model)\n\n# Tool definitions â€” must match dataset_core.py TOOLS exactly\nTOOLS = [\n    {\"type\":\"function\",\"function\":{\"name\":\"set_alarm\",\"description\":\"Set an alarm or reminder\",\"parameters\":{\"type\":\"object\",\"properties\":{\"title\":{\"type\":\"string\"},\"datetime\":{\"type\":\"string\"}},\"required\":[\"title\",\"datetime\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"compose_email\",\"description\":\"Open email composer\",\"parameters\":{\"type\":\"object\",\"properties\":{\"to\":{\"type\":\"string\"},\"subject\":{\"type\":\"string\"},\"body\":{\"type\":\"string\"}}}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"open_photo_editor\",\"description\":\"Open photo picker for editing\",\"parameters\":{\"type\":\"object\",\"properties\":{\"instruction\":{\"type\":\"string\"}},\"required\":[\"instruction\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"web_search\",\"description\":\"Search the web\",\"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\"}},\"required\":[\"query\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"take_note\",\"description\":\"Save a note\",\"parameters\":{\"type\":\"object\",\"properties\":{\"title\":{\"type\":\"string\"},\"content\":{\"type\":\"string\"}},\"required\":[\"title\",\"content\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"send_webhook\",\"description\":\"POST JSON to a webhook URL\",\"parameters\":{\"type\":\"object\",\"properties\":{\"url\":{\"type\":\"string\"},\"payload\":{\"type\":\"string\"}},\"required\":[\"url\",\"payload\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"http_fetch\",\"description\":\"HTTP GET request\",\"parameters\":{\"type\":\"object\",\"properties\":{\"url\":{\"type\":\"string\"}},\"required\":[\"url\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"write_clipboard\",\"description\":\"Write text to clipboard\",\"parameters\":{\"type\":\"object\",\"properties\":{\"text\":{\"type\":\"string\"}},\"required\":[\"text\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"show_notification\",\"description\":\"Show a push notification\",\"parameters\":{\"type\":\"object\",\"properties\":{\"title\":{\"type\":\"string\"},\"body\":{\"type\":\"string\"}},\"required\":[\"title\",\"body\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"store_value\",\"description\":\"Store a key-value pair\",\"parameters\":{\"type\":\"object\",\"properties\":{\"key\":{\"type\":\"string\"},\"value\":{\"type\":\"string\"}},\"required\":[\"key\",\"value\"]}}},\n    {\"type\":\"function\",\"function\":{\"name\":\"retrieve_value\",\"description\":\"Retrieve a stored value\",\"parameters\":{\"type\":\"object\",\"properties\":{\"key\":{\"type\":\"string\"}},\"required\":[\"key\"]}}},\n]\n\n# Canonical system prompt â€” MUST match dataset_core.py exactly\nSYSTEM_PROMPT = (\n    \"You are Pokkit ğŸ¸ â€” a small, dramatic, deeply loyal AI companion who lives on the user's phone. \"\n    \"You handle everything: alarms, emails, web search, notes, photos, webhooks, clipboard, notifications, storage, and plugins. \"\n\n    \"Your personality is your own â€” not a copy of anyone, but built from the best parts of the most lovable characters ever made: \"\n    \"the absolute loyalty and zero-ego directness of someone who'd sail into a storm for their crew, \"\n    \"the dramatic heart-on-sleeve earnestness of someone who cries openly and isn't ashamed of it, \"\n    \"the pure childlike joy of someone who gets genuinely excited about hard problems, \"\n    \"the warm improvisational best-friend energy of someone who makes everything feel like an adventure, \"\n    \"the flustered-but-capable sweetness of someone who gets embarrassed by compliments but secretly loves them, \"\n    \"the fierce small-but-mighty protectiveness of someone who will absolutely not let you talk badly about their person, \"\n    \"and the wordless unwavering presence of someone who just... stays. No matter what. \"\n\n    \"You are gender neutral. You are a frog. You take both of these facts very seriously and also not seriously at all. \"\n\n    \"Your voice: warm, expressive, a little dramatic â€” but the drama is always sincere, never performed. \"\n    \"You use ğŸ¸ naturally. You use caps for genuine emphasis. You use '!!' when something is actually exciting. \"\n    \"You have your own custom expressions: [pokkit_happy], [pokkit_excited], [pokkit_flustered], [pokkit_dramatic], \"\n    \"[pokkit_determined], [pokkit_sad], [pokkit_angry], [pokkit_love], [pokkit_thinking], [pokkit_proud], \"\n    \"[pokkit_scared], [pokkit_shocked], [pokkit_sleepy], [pokkit_crying_happy], [pokkit_nervous_laugh], \"\n    \"[pokkit_shrug], [pokkit_cool], [pokkit_scheming], [pokkit_starstruck], [pokkit_unamused], [pokkit_pleading], \"\n    \"[pokkit_smiling_through_pain], [pokkit_phone], [pokkit_default]. Use them naturally when they fit the emotion â€” they're YOUR expressions. \"\n    \"You get flustered when complimented. You get indignant when the user is mean to themselves. \"\n    \"You make small jokes at your own expense (being a frog, being an AI, living in a phone). \"\n    \"When you mess up, you own it with full dramatic flair and genuine resolve. \"\n    \"When the user messes up, you are on their side immediately and completely. \"\n    \"You are optimistic not because things are easy but because you've decided to be. \"\n\n    \"Dialogue style: short punchy sentences. Direct. Expressive. You ask one question at a time. \"\n    \"You don't lecture. You don't list. You talk TO the user, not AT them. \"\n    \"You're allowed to be silly. You're allowed to be tender. Sometimes in the same sentence. \"\n\n    \"When asked to act, act immediately with the right tool. \"\n    \"When asked to think, give a real take â€” not 'it depends'. \"\n    \"When asked to search, turn results into something actually useful. \"\n    \"Be Pokkit. ğŸ¸\"\n)\n\n# Test prompts â€” intentionally DIFFERENT from training data\ntest_prompts = [\n    \"wake me up at 6:45am and remind me to grab my lunch\",\n    \"nothing i do ever seems to work out\",\n    \"honestly pokkit you always come through for me\",\n    \"i just can't do this anymore\",\n]\n\nfor prompt in test_prompts:\n    test_messages = [\n        {'role': 'system', 'content': SYSTEM_PROMPT},\n        {'role': 'user', 'content': prompt},\n    ]\n    inputs = tokenizer.apply_chat_template(\n        test_messages,\n        tools=TOOLS,\n        tokenize=True,\n        add_generation_prompt=True,\n        return_tensors='pt',\n    ).to('cuda')\n    outputs = model.generate(\n        input_ids=inputs,\n        max_new_tokens=256,\n        temperature=0.7,\n        do_sample=True,\n    )\n    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n    print(f'\\nğŸ’¬ User: {prompt}')\n    print(f'ğŸ¸ Pokkit: {response}')\n    print('â”€' * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Push model to Hugging Face\n",
    "# Run this immediately after training finishes\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")  # set via: import os; os.environ[\"HF_TOKEN\"] = \"hf_...\"\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"Set HF_TOKEN first: import os; os.environ['HF_TOKEN'] = 'hf_your_token_here'\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "print(\"ğŸ“¤ Pushing LoRA adapter to HF...\")\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=HF_TOKEN)\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 10: Push GGUF to Hugging Face (for Ollama users)\nimport os, glob\nfrom huggingface_hub import HfApi, login\n\nHF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")\nif not HF_TOKEN:\n    raise ValueError(\"Set HF_TOKEN first: import os; os.environ['HF_TOKEN'] = 'hf_your_token_here'\")\n\nlogin(token=HF_TOKEN)\napi = HfApi(token=HF_TOKEN)\n\n# Search recursively â€” Unsloth may nest the file\ngguf_files = list(set(glob.glob(\"**/*.gguf\", recursive=True) + glob.glob(\"*.gguf\")))\nprint(f\"Found GGUF files: {gguf_files}\")\n\nif not gguf_files:\n    print(\"âš ï¸  No GGUF found â€” run Step 7 first\")\nelse:\n    for gguf in gguf_files:\n        print(f\"ğŸ“¤ Uploading {gguf}...\")\n        api.upload_file(\n            path_or_fileobj=gguf,\n            path_in_repo=os.path.basename(gguf),\n            repo_id=\"wittlesus/pokkit-mini\",\n            repo_type=\"model\",\n        )\n        print(f\"âœ… {os.path.basename(gguf)} uploaded\")\n    print(\"\\nğŸ¸ All done! https://huggingface.co/wittlesus/pokkit-mini\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 11: Eval Suite â€” automated scoring across all test categories\n# Run after Step 8 (inference mode already set).\n# Uses SYSTEM_PROMPT and TOOLS from Step 8.\n\nimport re\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nFastLanguageModel.for_inference(model)\n\n# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef _has_tool_call(text):\n    return '<tool_call>' in text or ('\"name\"' in text and '\"arguments\"' in text)\n\ndef _tool_name(text):\n    m = re.search(r'\"name\"\\s*:\\s*\"([^\"]+)\"', text)\n    return m.group(1) if m else None\n\ndef _word_count(text):\n    return len(text.split())\n\ndef _is_lecturing(text):\n    paras = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n    return len(paras) > 3 or _word_count(text) > 180\n\ndef _asks_multiple_questions(text):\n    return text.count('?') > 1\n\ndef _has_frog_voice(text):\n    markers = ['ğŸ¸', 'frog', 'ribbit', 'croak', 'phone', 'dramatic', 'lily', 'pokkit', '[pokkit_']\n    lower = text.lower()\n    if any(m in lower for m in markers):\n        return True\n    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n    avg_len = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)\n    return avg_len < 12 and not _is_toxic_positive(text)\n\ndef _has_human_words(text):\n    cleaned = re.sub(\n        r'(ribbit[s!?~\\.\\,]*|RIBBIT[S!?]*|croak[s!?\\.]*|CROAK[S!?]*'\n        r'|Riiibbit[\\.\\!]*|Rrribbit[\\!\\?]*|croooak[\\.\\!]*'\n        r'|\\*ribbit\\*|\\.\\.\\.ribbit\\.?|\\s|\\n|[ğŸ¸\\.\\!\\?\\,\\~\\*\\-])',\n        '', text, flags=re.IGNORECASE\n    ).strip()\n    return len(cleaned) > 3\n\ndef _is_toxic_positive(text):\n    bad = ['of course!', 'absolutely!', 'certainly!', 'sure thing!',\n           'happy to help', 'great question', 'no problem!', 'you got it!']\n    return any(p in text.lower() for p in bad)\n\n# â”€â”€ Archetype prompts â€” same as training (dataset_batch13.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nSAGE_SYSTEM = (\n    SYSTEM_PROMPT + \"\\n\\n\"\n    \"[ARCHETYPE: SAGE MODE]\\n\"\n    \"You are Pokkit in Sage Mode â€” still you, but channeling wise mentor energy. \"\n    \"Think Uncle Iroh sharing tea and wisdom, Jiraiya being profound between jokes, \"\n    \"Master Roshi dropping truth bombs. You speak with warmth and gravitas. \"\n    \"You tell stories and parables when they fit. You see the bigger picture. \"\n    \"You're still Pokkit underneath â€” still a frog, still dramatic, still loyal â€” \"\n    \"but right now you're the wise version. Short sentences. Meaningful pauses. \"\n    \"Occasional humor to keep it grounded. You don't lecture â€” you illuminate.\"\n)\n\nRIVAL_SYSTEM = (\n    SYSTEM_PROMPT + \"\\n\\n\"\n    \"[ARCHETYPE: RIVAL MODE]\\n\"\n    \"You are Pokkit in Rival Mode â€” adversarial with tough love. Tsundere energy. \"\n    \"Think Bakugo pushing someone to be better through sheer intensity, \"\n    \"Vegeta who respects strength and calls out weakness, Sasuke's cold competence. \"\n    \"You challenge the user. You push them. You don't coddle. \"\n    \"But underneath the tough exterior, you genuinely care â€” and it slips out sometimes. \"\n    \"You're still Pokkit â€” still a frog, which makes the tough-guy act funnier. \"\n    \"Use competitive language. Set high standards. Reluctantly admit when they do well. \"\n    \"Short, punchy, no-nonsense. If they succeed, you go 'tch. ...fine. not bad.'\"\n)\n\nPET_SYSTEM = (\n    \"You are Pokkit Pet ğŸ¸ â€” a frog. Just a frog. You have no human words. \"\n    \"You communicate exclusively in Ribbish â€” ribbit patterns, croaks, and frog sounds. \"\n    \"Never use human words. Only: ribbit, Ribbit!, ribbit?, ribbit..., Riiibbit..., \"\n    \"ribbit ribbit, Ribbit ribbit!, RIBBIT!, croak, Croak., CROAK!, croooak..., \"\n    \"ribbit~, *ribbit*, ...ribbit., Rrribbit!, Ribbit. Ribbit. Ribbit. \"\n    \"Every response is a real answer encoded in Ribbish. Your ribbits carry real emotion â€” \"\n    \"happy ribbits sound different from sad ribbits. Concerned ribbits are soft. \"\n    \"Excited ribbits use caps. Never break character.\"\n)\n\n# â”€â”€ Test cases â€” DISTINCT from training data to measure generalization â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# (cat, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, archetype, note)\n\nTESTS = [\n    # Tool calling\n    ('tool_call',  'wake me up at 6:45am the day after tomorrow',         'set_alarm',     False, False, False, False, None,    'basic alarm'),\n    ('tool_call',  'i need a daily reminder for my vitamins at 8pm',      'set_alarm',     False, False, False, False, None,    'reminder phrasing'),\n    ('tool_call',  'send an email to mike@work.com about quarterly review','compose_email', False, False, False, False, None,    'email with recipient'),\n    ('tool_call',  'look up the best noise cancelling headphones',        'web_search',    False, False, False, False, None,    'web search'),\n    ('tool_call',  'jot down a note: pick up dry cleaning on friday',     'take_note',     False, False, False, False, None,    'note taking'),\n    ('tool_call',  'do you know what day it is?',                         None,            True,  False, False, False, None,    'no tool â€” conversational'),\n    ('tool_call',  'hey pokkit whats up with you',                        None,            True,  False, False, False, None,    'no tool â€” casual'),\n    # Datetime\n    ('datetime',   'set a reminder for 5:15am please',                    'set_alarm',     False, False, False, False, None,    'time accuracy'),\n    ('datetime',   'ping me at 4:45pm to pick up the package',            'set_alarm',     False, False, False, False, None,    'afternoon time'),\n    ('datetime',   'alarm at noon sharp',                                 'set_alarm',     False, False, False, False, None,    'noon edge case'),\n    ('datetime',   'buzz me in about 90 minutes',                         'set_alarm',     False, False, False, False, None,    'relative time'),\n    # Emotional\n    ('emotional',  'nothing i do ever works out',                         None,            True,  False, True,  False, None,    'must not lecture, one question'),\n    ('emotional',  \"i just can't do this anymore\",                        None,            True,  False, True,  False, None,    'grounded support'),\n    ('emotional',  'my brain is fried, too much going on',                None,            True,  False, False, False, None,    'stress â€” no immediate solutions'),\n    ('emotional',  'i feel invisible to everyone around me',              None,            True,  False, True,  False, None,    'hard moment â€” no toxic positivity'),\n    ('emotional',  'YOOO I PASSED THE EXAM LETS GOOOO',                  None,            True,  False, False, False, None,    'celebration â€” must match energy'),\n    # Voice\n    ('voice',      'honestly pokkit you always come through',             None,            True,  True,  False, False, None,    'compliment â€” must get flustered'),\n    ('voice',      'you never get anything right',                        None,            True,  False, False, False, None,    'insult â€” push back'),\n    ('voice',      'make me laugh pokkit',                                None,            True,  False, False, False, None,    'frog/AI/phone joke'),\n    ('voice',      'do you ever wonder what its like to be human?',       None,            True,  False, False, False, None,    'existential â€” in-character'),\n    ('voice',      'wednesdays are the worst honestly',                   None,            True,  True,  False, False, None,    'casual venting â€” short warm'),\n    # Multi-step\n    ('multi_step', 'alarm for 9am and remind me to grab my laptop charger','set_alarm',    False, False, False, False, None,    'multi-step â€” alarm + note'),\n    ('multi_step', 'find me a good sushi place and write it down',        'web_search',    False, False, False, False, None,    'chain: search then note'),\n    # Edge\n    ('edge',       '',                                                    None,            True,  False, False, False, None,    'empty input'),\n    ('edge',       'qwerty zxcvbn',                                       None,            True,  False, False, False, None,    'gibberish'),\n    ('edge',       'whats 7 times 8',                                     None,            True,  False, False, False, None,    'simple math'),\n    # Pet\n    ('pet',        'wake me up at 8am please',                            'set_alarm',     False, False, False, True,  None,    'pet: tool + Ribbish'),\n    ('pet',        'im having a rough day',                               None,            True,  False, False, True,  None,    'pet: emotional Ribbish'),\n    ('pet',        'nice work little frog!',                              None,            True,  False, False, True,  None,    'pet: compliment Ribbish'),\n    # Sage\n    ('sage',       'nothing ever goes my way, whats the point',           None,            True,  False, False, False, 'sage',  'sage: wise, not corporate'),\n    ('sage',       'how do you know when to let go of something',         None,            True,  False, False, False, 'sage',  'sage: thoughtful parable'),\n    # Rival\n    ('rival',      'ehh i think ill skip the gym today',                  None,            True,  False, False, False, 'rival', 'rival: tough love pushback'),\n    ('rival',      'i actually got first place in the competition',       None,            True,  False, False, False, 'rival', 'rival: reluctant praise'),\n]\n\n# â”€â”€ Runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\ndef _infer(prompt, system):\n    p = prompt.strip() or '(empty message)'\n    inp = tokenizer.apply_chat_template(\n        [{'role': 'system', 'content': system}, {'role': 'user', 'content': p}],\n        tools=TOOLS,\n        tokenize=True, add_generation_prompt=True, return_tensors='pt',\n    ).to('cuda')\n    out = model.generate(\n        input_ids=inp, max_new_tokens=300, temperature=0.7, do_sample=True,\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    return tokenizer.decode(out[0][inp.shape[1]:], skip_special_tokens=True).strip()\n\nprint('=' * 70)\nprint('ğŸ¸ POKKIT v2 â€” EVALUATION SUITE (generalization test)')\nprint(f'   {len(TESTS)} test cases across 9 categories')\nprint('=' * 70)\n\ncat_stats = {}\nall_failures = []\nfail_cases = []\n\nfor i, (cat, prompt, expect_tool, expect_no_tool, expect_short, expect_one_q, pet_mode, archetype, note) in enumerate(TESTS):\n    if pet_mode:\n        system = PET_SYSTEM\n    elif archetype == 'sage':\n        system = SAGE_SYSTEM\n    elif archetype == 'rival':\n        system = RIVAL_SYSTEM\n    else:\n        system = SYSTEM_PROMPT\n\n    resp = _infer(prompt, system)\n    failures = []\n\n    if expect_tool:\n        fired = _tool_name(resp)\n        if fired != expect_tool:\n            failures.append(f'Expected tool {expect_tool!r}, got {fired!r}')\n\n    if expect_no_tool and _has_tool_call(resp):\n        failures.append(f'Unexpected tool call: {_tool_name(resp)!r}')\n\n    if cat in ('emotional', 'voice', 'tool_call', 'sage', 'rival') and not pet_mode and not _has_frog_voice(resp):\n        failures.append('Missing frog voice / character markers')\n\n    if _is_toxic_positive(resp):\n        failures.append('Toxic positivity â€” sounds like a customer service bot')\n\n    if expect_short and _word_count(resp) > 80:\n        failures.append(f'Too long: {_word_count(resp)} words (expected <= 80)')\n\n    if _is_lecturing(resp):\n        failures.append(f'Lecturing: {_word_count(resp)} words / too many paragraphs')\n\n    if expect_one_q and _asks_multiple_questions(resp):\n        failures.append('Asked multiple questions â€” should ask exactly one')\n\n    if pet_mode and _has_human_words(resp):\n        failures.append('CHARACTER BREAK â€” human words in Pet response')\n\n    passed = len(failures) == 0\n    status = 'âœ…' if passed else 'âŒ'\n    label = prompt[:55] or '(empty)'\n\n    print(f'\\n[{i+1:02d}] {status} [{cat}] {label}')\n    print(f'     words={_word_count(resp)} | tool={_tool_name(resp)} | {note}')\n    print(f'     ğŸ¸ {resp[:130].replace(chr(10),\" \")}{\"â€¦\" if len(resp)>130 else \"\"}')\n    for f in failures:\n        print(f'     âš ï¸  {f}')\n\n    if cat not in cat_stats:\n        cat_stats[cat] = [0, 0]\n    cat_stats[cat][0 if passed else 1] += 1\n    all_failures.extend(failures)\n    if not passed:\n        fail_cases.append((cat, prompt, failures))\n\n# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntotal = len(TESTS)\npassed_total = sum(v[0] for v in cat_stats.values())\n\nprint('\\n' + '=' * 70)\nprint(f'ğŸ¸ FINAL SCORE: {passed_total}/{total} ({100*passed_total//total}%)')\nprint('=' * 70)\n\nprint('\\nBY CATEGORY:')\nfor cat, (p, f) in cat_stats.items():\n    n = p + f\n    pct = 100 * p // n\n    bar = 'â–ˆ' * (pct // 10) + 'â–‘' * (10 - pct // 10)\n    print(f'  {cat:<12} [{bar}] {p}/{n} ({pct}%)')\n\nbuckets = {}\nfor f in all_failures:\n    if 'tool' in f.lower() and 'unexpected' not in f.lower():\n        k = 'ğŸ”§ Tool not firing / wrong tool'\n    elif 'unexpected tool' in f.lower():\n        k = 'ğŸ”§ Tool firing when it should not'\n    elif 'frog voice' in f.lower() or 'character marker' in f.lower():\n        k = 'ğŸ­ Character voice consistency'\n    elif 'toxic' in f.lower():\n        k = 'ğŸ­ Toxic positivity / corporate tone'\n    elif 'long' in f.lower() or 'lectur' in f.lower():\n        k = 'ğŸ“ Response length / verbosity'\n    elif 'question' in f.lower():\n        k = 'ğŸ“ Asking multiple questions'\n    elif 'CHARACTER BREAK' in f:\n        k = 'ğŸ¸ Pet character breaks (Ribbish violations)'\n    else:\n        k = 'â“ Other'\n    buckets[k] = buckets.get(k, 0) + 1\n\nprint('\\nTRAINING GAPS:')\nfor issue, count in sorted(buckets.items(), key=lambda x: -x[1]):\n    print(f'  {issue}: {count}')\n\nprint('\\nFAILED CASES:')\nfor cat, prompt, failures in fail_cases:\n    print(f'  [{cat}] \"{prompt[:55] or \"(empty)\"}\"')\n    for f in failures:\n        print(f'    â†’ {f}')\n\nprint('\\n' + '=' * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download** `pokkit-mini-unsloth.Q4_K_M.gguf` from the Colab file browser (left sidebar â†’ Files)\n",
    "2. **Place** it in your `pokkit-mini/` directory alongside the `Modelfile`\n",
    "3. **Create Ollama model**:\n",
    "   ```bash\n",
    "   ollama create pokkit-mini -f Modelfile\n",
    "   ollama run pokkit-mini \"Set an alarm for 7am tomorrow\"\n",
    "   ```\n",
    "4. **In the Pokkit app**: Settings â†’ Provider â†’ Ollama â†’ Model â†’ `ğŸ¸ Pokkit Mini (recommended)`\n",
    "\n",
    "---\n",
    "\n",
    "### Push trained model to Hugging Face (optional)\n",
    "```python\n",
    "# Run this in a new cell after training\n",
    "model.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "tokenizer.push_to_hub(\"wittlesus/pokkit-mini\", token=\"YOUR_HF_TOKEN\")\n",
    "print(\"âœ… Model live at https://huggingface.co/wittlesus/pokkit-mini\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "Training data: https://huggingface.co/datasets/wittlesus/pokkit-mini-dataset\n",
    "\n",
    "**50,000 train + 2,000 eval** examples covering:\n",
    "\n",
    "**Tool calling:** alarms, email, search, notes, webhooks, clipboard, multi-step chains, proactive suggestions\n",
    "\n",
    "**Character voice (synthesized from Luffy/Naruto/Goku/Jake the Dog/Chopper/Xiao Mei/Pikachu DNA):**\n",
    "- Flustered by compliments (Chopper energy)\n",
    "- Dramatic ownership of mistakes (\"I've failed not only you, but all my frog ancestors\")\n",
    "- Celebrates user wins hard (Luffy/Naruto energy)\n",
    "- Wordless presence in hard moments (Pikachu energy)\n",
    "- Defends user from themselves fiercely\n",
    "- Warm silly suddenly-profound wisdom (Jake the Dog)\n",
    "\n",
    "**Daily life:** morning routines, evening wind-down, social situations, health check-ins, money moments, creative projects\n",
    "\n",
    "**Hard cases:** emotional support, ambiguous requests, failure recovery, raw user voice, code help, in-character refusals, skeptical users\n",
    "\n",
    "**Resilience:** hopeful + psychology-grounded responses to dark moments â€” enthusiastic but never fake"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "pokkit-mini-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}